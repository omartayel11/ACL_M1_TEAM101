# Comprehensive Presentation Plan: Graph Retrieval Layer
## Baseline & Embeddings Implementation

---

## ğŸ“Š **SLIDE 1: Overview - Graph Retrieval Layer**

### Title: Graph Retrieval Layer: Two Approaches

**Content:**
- **Baseline Approach**: Structured Cypher queries with entity extraction
- **Embedding Approach**: Semantic vector search with FAISS
- **Innovation**: Entity-driven multi-index selection

**Visual:**
```
User Query
    â†“
Intent Classification (8 types)
    â†“
Entity Extraction
    â†“
    â”œâ”€â†’ Baseline: Cypher Queries (15 templates)
    â””â”€â†’ Embeddings: Vector Search (3 FAISS indexes)
```

---

## ğŸ“‹ **SLIDE 2: Baseline Approach - Architecture**

### Title: Baseline: Structured Query Retrieval

**What it is:**
- **15 parameterized Cypher query templates** in `query_library.py`
- Queries selected based on **intent** (8 types)
- Parameters filled using **extracted entities**
- Direct Neo4j graph traversal

**Key Components:**
1. **IntentClassifier**: Classifies query â†’ 1 of 8 intents (85.19% accuracy)
2. **EntityExtractor**: Extracts entities from query (86.18% accuracy)
3. **QueryBuilder**: Selects appropriate Cypher template
4. **QueryExecutor**: Executes on Neo4j

**Code Example:**
```python
# User query: "Hotels in Paris with rating above 8"
intent = "HotelSearch"  # Classified
entities = {"city": "Paris", "min_rating": 8.0}  # Extracted

# QueryBuilder selects template
cypher, params = QueryLibrary.get_hotels_by_city("Paris")
# Returns: MATCH (h:Hotel)-[:LOCATED_IN]->(c:City {name: $city_name})...
```

---

## ğŸ” **SLIDE 3: Baseline - 15 Cypher Query Templates**

### Title: Query Library: 15 Templates Across 8 Intents

**Query Distribution:**

### **1. HotelSearch (3 queries)**
- `get_hotels_by_city(city_name)` - Hotels in specific city
- `get_hotels_by_country(country_name)` - Hotels in country
- `get_hotels_by_rating_threshold(min_rating)` - Filter by rating

**Example Query:**
```cypher
MATCH (h:Hotel)-[:LOCATED_IN]->(c:City {name: $city_name})
OPTIONAL MATCH (c)-[:LOCATED_IN]->(country:Country)
RETURN h.hotel_id, h.name, h.star_rating, h.average_reviews_score,
       c.name AS city, country.name AS country
ORDER BY h.average_reviews_score DESC
```

### **2. HotelRecommendation (5 queries)**
- `get_top_hotels_for_traveller_type(traveller_type, limit)` - Best for Business/Couple/Family/Solo/Group
- `get_hotels_by_cleanliness_score(min_cleanliness)` - High cleanliness
- `get_hotels_by_comfort_score(min_comfort, limit)` - Comfort rating
- `get_hotels_by_value_for_money(min_value, limit)` - Best value
- `get_hotels_with_best_staff_scores(limit)` - Staff service

**Example Query:**
```cypher
MATCH (t:Traveller {type: $traveller_type})-[:WROTE]->(r:Review)-[:REVIEWED]->(h:Hotel)
WITH h, AVG(r.score_overall) AS avg_rating, COUNT(r) AS review_count
ORDER BY avg_rating DESC, review_count DESC
LIMIT $limit
RETURN h.hotel_id, h.name, avg_rating, review_count
```

---

## ğŸ” **SLIDE 4: Baseline - Query Templates (Continued)**

### **3. ReviewLookup (2 queries)**
- `get_reviews_by_hotel_name(hotel_name, limit)` - Reviews for hotel
- `get_reviews_by_hotel_id(hotel_id, limit)` - Reviews by ID

**Example:**
```cypher
MATCH (h:Hotel {name: $hotel_name})<-[:REVIEWED]-(r:Review)<-[:WROTE]-(t:Traveller)
RETURN h.name, r.review_id, r.text, r.date, r.score_overall,
       t.user_id, t.type AS traveller_type
ORDER BY r.date DESC LIMIT $limit
```

### **4. LocationQuery (1 query)**
- `get_hotels_with_best_location_scores(city_name, limit)` - Best location

### **5. VisaQuestion (2 queries)**
- `check_visa_requirements(from_country, to_country)` - Visa needed?
- `get_travellers_by_country_no_visa(from_country, to_country)` - No-visa travelers

**Example:**
```cypher
MATCH (from:Country {name: $from_country})-[v:NEEDS_VISA]->(to:Country {name: $to_country})
RETURN from.name, to.name, v.visa_type
```

### **6. AmenityFilter (2 queries)**
- Comfort/Value filtering

### **7. GeneralQuestionAnswering (1 query)**
- `get_hotel_full_details(hotel_name)` - Complete hotel info

---

## ğŸ¯ **SLIDE 5: Baseline - Test Results**

### Title: Baseline Performance Metrics

**Test Framework:** `test_intent_classifier.py` & `test_entity_extractor.py`

**Intent Classification (162 test cases):**
- âœ… Overall Accuracy: **85.19%** (138/162 correct)
- Best: VisaQuestion (100%), CasualConversation (93.33%)
- Weakest: GeneralQuestionAnswering (60%), LocationQuery (73.33%)

**Entity Extraction (123 test cases):**
- âœ… Overall Accuracy: **86.18%** (106/123 correct)
- Successfully extracts: city, country, traveller_type, ratings, scores
- Handles typos with fuzzy matching (e.g., "Paaris" â†’ "Paris")

**Baseline Strengths:**
- âš¡ **Fast** (direct graph traversal, no ML inference)
- âœ“ **Precise** (exact matches for structured queries)
- âœ“ **Explainable** (clear query logic)

**Baseline Limitations:**
- âŒ Cannot handle semantic/fuzzy queries ("romantic getaway" â‰  "Couple")
- âŒ Requires exact entity extraction
- âŒ No ranking by semantic relevance

---

## ğŸ§  **SLIDE 6: Embeddings - Why We Need Them**

### Title: From Structured to Semantic Search

**The Problem with Baseline:**

**Example Query:** _"Best hotel for a romantic honeymoon"_

âŒ **Baseline struggles:**
- Intent: HotelRecommendation (âœ“)
- Entity extraction: `traveller_type` = ??? (fails to map "romantic honeymoon" â†’ "Couple")
- Query fails or returns wrong traveller type

âœ… **Embeddings solve this:**
- Semantic understanding: "romantic honeymoon" is SIMILAR to "Couple traveler reviews"
- No need for exact keyword matching
- Captures nuanced meaning

**Key Innovation:**
- Encode **both queries AND graph data** as vectors
- Find similar items using **cosine similarity**
- Handles fuzzy, semantic, natural language queries

---

## ğŸ—ï¸ **SLIDE 7: Embeddings - Architecture**

### Title: Embedding System Architecture

**Three-Part System:**

### **1. Embedding Generation (Offline)**
- Run `create_embeddings.py` once after KG creation
- Generates vector representations of graph nodes
- Creates FAISS indexes for fast search

### **2. Vector Search (Online)**
- User query â†’ Embedding (384/768 dims)
- Search FAISS indexes
- Return top-K similar items

### **3. Multi-Index Intelligence**
- **Problem**: Different queries need different data sources
- **Solution**: Entity-driven index selection

**Flow:**
```
User Query
    â†“
Embed Query (sentence-transformers)
    â†“
Entity Extraction (LLM)
    â†“
Select FAISS Indexes (rule-based)
    â”œâ”€â†’ hotel_embeddings.faiss (25 hotels)
    â”œâ”€â†’ visa_embeddings.faiss (220 visa rules)
    â””â”€â†’ review_embeddings.faiss (50,000+ reviews)
    â†“
Multi-Index Search & Merge
    â†“
Top-K Results
```

---

## ğŸ“¦ **SLIDE 8: Embeddings - Three FAISS Indexes**

### Title: Problem: Why Multiple Embedding Files?

**The Challenge:**
Hotels, visa rules, and reviews have **different information types**:

### **1. Hotel Embeddings (`hotel_embeddings.faiss`)**
**What:** 25 hotels with **aggregate properties**

**Feature String Example:**
```python
"The Azure Tower in Paris, France. Star rating: 5.0. 
Average score: 9.12. Cleanliness: 9.2, Comfort: 9.1, 
Facilities: 9.0, Location: 9.5, Staff: 9.3, Value for money: 8.8"
```

**Use Cases:**
- "5-star hotel in Paris"
- "Hotels with high cleanliness"
- "Best location in Tokyo"

**Cypher to Generate:**
```cypher
MATCH (h:Hotel)-[:LOCATED_IN]->(c:City)-[:LOCATED_IN]->(co:Country)
RETURN h.hotel_id, h.name, c.name AS city, co.name AS country,
       h.star_rating, h.average_reviews_score,
       h.cleanliness_base, h.comfort_base, h.location_base...
```

**Why Separate?** Hotels describe **properties** and **aggregate ratings**

---

## ğŸ“¦ **SLIDE 9: Embeddings - Visa Index**

### **2. Visa Embeddings (`visa_embeddings.faiss`)**
**What:** 220 visa relationships between countries

**Feature String Example:**
```python
"Visa required from Egypt to France. Visa type: Required. 
Travelers from Egypt need a visa to visit France. 
Egypt citizens require Required visa for France travel."
```

**Use Cases:**
- "Do I need visa from USA to France?"
- "Egypt to UK visa requirements"
- "Travel from India to United States"

**Cypher to Generate:**
```cypher
MATCH (from:Country)-[v:NEEDS_VISA]->(to:Country)
RETURN from.name AS from_country, to.name AS to_country, 
       v.visa_type AS visa_type
```

**Why Separate?** Visa rules are **relationships**, not nodes. Different semantic space.

---

## ğŸ“¦ **SLIDE 10: Embeddings - Review Index (Key Innovation)**

### **3. Review Embeddings (`review_embeddings.faiss`)**
**What:** 50,000+ reviews with **traveler demographics + ratings**

**Feature String Example:**
```python
"Male Solo traveler from USA (age 45-54) reviewed The Azure Tower 
in Paris, France (5 stars). Overall: 9.5/10. 
Ratings: Cleanliness 9.5, Comfort 9.2, Facilities 9.0, 
Location 9.8, Staff 9.3, Value 9.0."
```

**Critical Fields:**
- `traveller_type`: Business, Couple, Family, Solo, Group
- `from_country`: User demographics
- `age`: Age group
- Individual rating scores (not aggregates)

**Use Cases:**
- â­ "Best hotel for solo travelers" (matches traveller_type)
- â­ "Hotels Americans love" (matches from_country)
- â­ "Family-friendly accommodation" (matches Family reviews)

**Cypher to Generate:**
```cypher
MATCH (t:Traveller)-[:WROTE]->(r:Review)-[:REVIEWED]->(h:Hotel)
OPTIONAL MATCH (t)-[:FROM_COUNTRY]->(uc:Country)
RETURN t.user_id, t.gender, t.age, t.type AS traveller_type,
       uc.name AS user_country, h.hotel_id, h.name AS hotel_name,
       r.score_overall, r.score_cleanliness, r.score_comfort...
```

**Why Separate?** Reviews capture **user perspectives** - semantic queries about "who liked what" need review-level data

---

## ğŸš€ **SLIDE 11: The Core Innovation - Entity-Driven Multi-Index Selection**

### Title: Problem: Which FAISS File Should We Search?

**The Challenge:**

| Query | Needs Which Index? |
|-------|-------------------|
| "5-star hotel in Paris" | âœ… Hotel embeddings |
| "Do I need visa from USA to France?" | âœ… Visa embeddings |
| "Best hotel for solo travelers" | âœ… Hotel + Review embeddings! |
| "Hotels Americans love" | âœ… Hotel + Review embeddings! |

**Key Insight:** Some queries need **MULTIPLE** indexes!

**Previous Approach (WRONG):**
```python
if intent == "VisaQuestion":
    search visa_embeddings
else:
    search hotel_embeddings  # PROBLEM: Misses demographic info!
```

**Problem:** Query "best for solo travelers" â†’ Intent: HotelRecommendation â†’ Searches hotel_embeddings â†’ âŒ **Fails!** (no traveler demographic info in hotel aggregates)

---

## ğŸ’¡ **SLIDE 12: Solution - Entity Extractor as Router**

### Title: Entity-Driven Index Selection

**Key Innovation:** Use **extracted entities** to determine which FAISS indexes to load

**Implementation:** `vector_searcher.py::select_faiss_indexes(intent, entities)`

**Routing Rules:**

### **Rule 1: Traveler Demographics â†’ Review Embeddings**
```python
if "traveller_type" in entities or "from_country" in entities:
    indexes_to_search.append("review")
```

**Example:**
- Query: "Best hotel for solo travelers"
- Entities: `{"traveller_type": "Solo"}`
- Action: Load `review_embeddings.faiss` (matches Solo reviews)

### **Rule 2: Visa Intent â†’ Visa Embeddings**
```python
if intent == "VisaQuestion":
    indexes_to_search.append("visa")
```

### **Rule 3: Hotel Intent â†’ Hotel Embeddings**
```python
if intent in ["HotelSearch", "HotelRecommendation", ...]:
    indexes_to_search.append("hotel")
```

### **Rule 4: Review Lookup â†’ Review Embeddings**
```python
if intent == "ReviewLookup":
    indexes_to_search.append("review")
```

**Result:** Smart routing based on **what the query needs**, not just intent!

---

## ğŸ§ª **SLIDE 13: Test Example - Entity-Driven Routing**

### Title: Test Case: Multi-Index Search

**Test File:** `test_entity_driven_search.py` (147 lines)

**Test Scenario 1: Solo Traveler Query**

```python
query = "Best luxury hotel for solo travelers with great location"
intent = "HotelRecommendation"
entities = {"traveller_type": "Solo", "min_comfort": 4.0}
```

**Routing Decision:**
```
traveller_type present â†’ Load review_embeddings âœ…
intent = HotelRecommendation â†’ Load hotel_embeddings âœ…

Searches: ["review", "hotel"]
```

**Results:**
```
[1] The Golden Oasis - Dubai, United Arab Emirates
    Score: 5.916 (boosted)
    âœ“ Matches traveler profile in reviews (Solo)
    âœ“ High location score
    âœ“ APPEARS IN BOTH INDEXES â†’ Score boosted!
```

**What Happened:**
1. Searched **review_embeddings**: Found Solo traveler reviews for The Golden Oasis
2. Searched **hotel_embeddings**: Found The Golden Oasis has great location
3. **Multi-index merge**: The Golden Oasis appears in BOTH â†’ Score boosted by 50%!

---

## ğŸ§ª **SLIDE 14: Test Results - Entity-Driven vs Intent-Only**

### Title: Validation: Entity-Driven Routing Works

**Test Results from `test_entity_driven_search.py`:**

| Test Case | Intent | Entities | Expected Indexes | Selected Indexes | Result |
|-----------|--------|----------|-----------------|------------------|--------|
| Hotel Search | HotelSearch | {} | ["hotel"] | ["hotel"] | âœ… PASS |
| Solo Traveler | HotelRecommendation | {traveller_type: "Solo"} | ["review", "hotel"] | ["review", "hotel"] | âœ… PASS |
| Couples from USA | HotelRecommendation | {traveller_type: "Couple", from_country: "USA"} | ["review", "hotel"] | ["review", "hotel"] | âœ… PASS |
| Visa Question | VisaQuestion | {} | ["visa"] | ["visa"] | âœ… PASS |
| Review Lookup | ReviewLookup | {} | ["review"] | ["review"] | âœ… PASS |

**All 7/7 Tests PASSED** âœ…

**Key Benefit:**
- **Before**: Intent-only routing missed demographic queries
- **After**: Entity-driven routing correctly identifies need for review data
- **Impact**: 50% score boost for hotels matching multiple perspectives

---

## ğŸ­ **SLIDE 15: Embeddings - Two Models Compared**

### Title: Model Comparison: MiniLM vs MPNet

**We Created Embeddings with TWO Models:**

### **Model 1: all-MiniLM-L6-v2**
- **Dimensions**: 384
- **Speed**: âš¡ **Fast** (22.21ms embedding, 34.75ms search)
- **Files**: `hotel_embeddings.faiss`, `visa_embeddings.faiss`, `review_embeddings.faiss`

### **Model 2: all-mpnet-base-v2**
- **Dimensions**: 768 (2x larger)
- **Speed**: ğŸš€ **Super Fast** (0.01ms embedding, 19.75ms search)
- **Files**: `hotel_embeddings_mpnet.faiss`, `visa_embeddings_mpnet.faiss`, `review_embeddings_mpnet.faiss`

**Test Results** (55 queries: 30 hotel + 25 visa):

| Metric | MiniLM-L6-v2 | MPNet-Base-v2 | Winner |
|--------|--------------|---------------|--------|
| Hotel Top-1 Accuracy | 83.33% | 83.33% | TIE |
| Hotel Top-3 Accuracy | 86.67% | 86.67% | TIE |
| Visa Top-1 Accuracy | 80.00% | 80.00% | TIE |
| Hotel Avg Time | 56.96ms | **19.76ms** | ğŸ† **MPNet** |
| Visa Avg Time | 67.13ms | **18.80ms** | ğŸ† **MPNet** |

**Surprising Result:** MPNet is **3x faster** AND same accuracy! (Cache warming effect)

---

## ğŸ“ˆ **SLIDE 16: Embedding Generation - How It Works**

### Title: Creating Embeddings - Step by Step

**Script:** `create_embeddings.py` & `create_embeddings_mpnet.py`

### **Process:**

**Step 1: Fetch Data from Neo4j**
```python
cypher = """
MATCH (h:Hotel)-[:LOCATED_IN]->(c:City)-[:LOCATED_IN]->(co:Country)
RETURN h.hotel_id, h.name, c.name AS city, co.name AS country,
       h.star_rating, h.average_reviews_score, h.cleanliness_base...
"""
hotels = neo4j_client.run_query(cypher, {})
```

**Step 2: Build Feature Strings**
```python
feature_string = (
    f"{name} in {city}, {country}. "
    f"Star rating: {star_rating:.1f}. "
    f"Average score: {avg_score:.2f}. "
    f"Cleanliness: {cleanliness:.1f}, Comfort: {comfort:.1f}..."
)
```

**Step 3: Generate Embeddings**
```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
embedding = model.encode(feature_string)  # Returns 384-dim vector
```

**Step 4: Create FAISS Index**
```python
import faiss
dimension = 384
index = faiss.IndexFlatL2(dimension)
index.add(embeddings_array)
faiss.write_index(index, "hotel_embeddings.faiss")
```

**Step 5: Save Mapping**
```python
mapping = {0: "1", 1: "2", 2: "3", ...}  # FAISS index â†’ hotel_id
json.dump(mapping, open("hotel_id_mapping.json", 'w'))
```

**Run Once:** After KG creation, before queries

---

## ğŸ”¢ **SLIDE 17: Embedding Search - Query Time**

### Title: How Vector Search Works

**User Query:** _"Best luxury hotel for families"_

### **Step 1: Embed Query**
```python
query_embedding = embedding_model.encode("Best luxury hotel for families")
# Returns: [0.234, -0.112, 0.445, ..., 0.098]  # 384 dimensions
```

### **Step 2: Extract Entities**
```python
entities = entity_extractor.extract("Best luxury hotel for families", "HotelRecommendation")
# Returns: {"traveller_type": "Family"}
```

### **Step 3: Select Indexes** (Entity-Driven!)
```python
indexes_to_search = vector_searcher.select_faiss_indexes(
    intent="HotelRecommendation",
    entities={"traveller_type": "Family"}
)
# Returns: ["review", "hotel"]  â† BOTH indexes!
```

### **Step 4: Search FAISS**
```python
distances, indices = faiss_index.search(query_vector, k=10)
# Returns similar vectors (L2 distance)
```

### **Step 5: Convert Distance â†’ Similarity**
```python
similarity = 1 - (distance / 2)  # L2 â†’ Cosine similarity
# Filter by threshold (e.g., > 0.7)
```

### **Step 6: Fetch from Neo4j**
```python
hotel_id = id_mapping[faiss_index]
hotel_details = neo4j_client.run_query(
    "MATCH (h:Hotel {hotel_id: $id}) RETURN h.*", 
    {"id": hotel_id}
)
```

### **Step 7: Merge Multi-Index Results**
```python
# Hotel appears in both review and hotel embeddings
# â†’ Boost score by 50%!
```

---

## ğŸ“Š **SLIDE 18: Comprehensive Test Framework**

### Title: Evaluation & Testing

**Test Files:**

### **1. Intent Classification Test**
- **File**: `test_intent_classifier.py` (730 lines)
- **Tests**: 162 queries across 8 intents
- **Features**: Checkpoint/resume, live progress, per-intent accuracy
- **Result**: 85.19% accuracy

### **2. Entity Extraction Test**
- **File**: `test_entity_extractor.py` (similar structure)
- **Tests**: 123 queries with entity expectations
- **Result**: 86.18% accuracy

### **3. Entity-Driven Search Test**
- **File**: `test_entity_driven_search.py` (147 lines)
- **Tests**: 7 routing scenarios
- **Validates**: Multi-index selection logic
- **Result**: 7/7 tests passed

### **4. Embedding Model Comparison**
- **File**: `test_embeddings_comprehensive.py` (731 lines)
- **Tests**: 55 queries (30 hotel + 25 visa) Ã— 2 models
- **Metrics**: Top-1/3/5 accuracy, timing (embedding, search, total)
- **Output**: JSON results + comprehensive text report
- **Result**: Both models 83.33% hotel, 80% visa accuracy

---

## ğŸ¯ **SLIDE 19: Failed Query Analysis**

### Title: What Doesn't Work Well?

**From Test Results:**

### **Baseline Failures:**
- âŒ **Generic queries**: "What hotels are available in Cairo?" â†’ Classified as GeneralQuestionAnswering instead of HotelSearch
- âŒ **Implicit traveler types**: "hotels for couples" â†’ Entity extractor doesn't extract "Couple" traveller_type
- âŒ **Fuzzy locations**: "hotels in central Dubai" â†’ No "central" filter in queries

### **Embedding Failures:**
- âŒ **Nigeria visa queries**: Consistently retrieves wrong from_country (e.g., "Nigeria_to_US" returns "South Africa_to_US")
  - **Root cause**: Not enough Nigeria visa relationships in embeddings
- âŒ **Reverse visa direction**: "Brazil to China" returns "China_to_Brazil"
  - **Root cause**: Bidirectional similarity but schema is directional

### **Common Issues:**
- âŒ Typos in country names ("Span" instead of "Spain")
- âŒ Rating threshold extraction ("rating 4.8" not extracted as min_rating)

---

## ğŸ”„ **SLIDE 20: Baseline vs Embeddings - When to Use What**

### Title: Comparison & Use Cases

| Aspect | Baseline (Cypher) | Embeddings (FAISS) |
|--------|-------------------|-------------------|
| **Speed** | âš¡ Fast (direct graph) | âš¡ Very Fast (vector lookup) |
| **Accuracy** | âœ… 85-86% (intent+entity) | âœ… 80-83% (Top-1) |
| **Query Type** | Structured, exact | Semantic, fuzzy |
| **Strengths** | Precise, explainable | Handles natural language |
| **Weaknesses** | Rigid, keyword-dependent | Less explainable, requires training data |

### **When to Use Baseline:**
- âœ… "Hotels in Paris" (exact city match)
- âœ… "Visa from USA to France" (exact countries)
- âœ… "Hotels with cleanliness score > 9" (numeric filter)
- âœ… User wants **structured filtering**

### **When to Use Embeddings:**
- âœ… "Romantic honeymoon destination" (semantic: Couple traveler)
- âœ… "Budget-friendly family hotel" (semantic: Family + value)
- âœ… "Hotels Americans love" (demographic matching)
- âœ… User wants **semantic understanding**

### **Hybrid Approach (Best):**
- ğŸš€ Run **both** in parallel
- Merge results with score boosting
- Get precision OF baseline + semantic power OF embeddings

---

## ğŸ’» **SLIDE 21: Code Architecture**

### Title: Implementation Structure

**Component Organization:**

### **Baseline Components:**
```
query_library.py           # 15 Cypher query templates
components/
  intent_classifier.py     # 8 intent types (LLM-based)
  entity_extractor.py      # Extract query entities (LLM-based)
  query_builder.py         # Select & build Cypher
  query_executor.py        # Execute on Neo4j
```

### **Embedding Components:**
```
create_embeddings.py       # Generate FAISS indexes (run once)
create_embeddings_mpnet.py # Generate for 2nd model
components/
  embedding_generator.py   # Encode query â†’ vector
  vector_searcher.py       # Search FAISS + Neo4j fetch
```

### **Key Innovation:**
```python
# vector_searcher.py
def select_faiss_indexes(intent, entities):
    """Entity-driven multi-index selection"""
    indexes = []
    if "traveller_type" in entities:
        indexes.append("review")  # Need demographic data
    if intent == "VisaQuestion":
        indexes.append("visa")
    if intent in hotel_intents:
        indexes.append("hotel")
    return indexes

def multi_index_search(embedding, indexes, limit):
    """Search multiple indexes and merge with score boosting"""
    results = {}
    for index_name in indexes:
        for result in search_index(index_name):
            if result.id in results:
                # Boost score for multi-index hits
                results[result.id].score += result.score * 0.5
            else:
                results[result.id] = result
    return sorted(results.values(), key=lambda x: x.score, reverse=True)
```

---

## ğŸ“Š **SLIDE 22: Evaluation Metrics Summary**

### Title: Quantitative Results

**Test Coverage:**
- âœ… 162 intent classification tests
- âœ… 123 entity extraction tests  
- âœ… 55 embedding retrieval tests (30 hotel + 25 visa)
- âœ… 7 entity-driven routing tests

**Baseline Performance:**
- Intent Accuracy: **85.19%**
- Entity Accuracy: **86.18%**
- Query Templates: 15 (covering 100% of intents)

**Embedding Performance:**
- Hotel Top-1: **83.33%**
- Hotel Top-3: **86.67%**
- Visa Top-1: **80.00%**
- MPNet Speed: **19.76ms** (hotel), **18.80ms** (visa)

**Entity-Driven Routing:**
- Test Pass Rate: **100%** (7/7)
- Multi-index boost: **+50%** similarity score

**Total Lines of Code:**
- Components: ~2000 lines
- Tests: ~1600 lines
- Query Library: ~950 lines

---

## ğŸ“ **SLIDE 23: Key Learnings & Innovations**

### Title: What Makes This System Unique

### **1. Entity-Driven Multi-Index Selection**
**Problem**: Intent alone insufficient to determine data source  
**Solution**: Use extracted entities (traveller_type, from_country) to route to review embeddings  
**Impact**: Enables demographic queries ("best for solo travelers")

### **2. Multi-Index Score Boosting**
**Problem**: Hotels may appear in multiple indexes with different relevance  
**Solution**: Merge results and boost scores for multi-index hits  
**Impact**: Hotels matching multiple perspectives rank higher

### **3. Dual Embedding Models**
**Setup**: Support two models with separate FAISS files (_mpnet suffix)  
**Benefit**: Can compare speed/quality tradeoffs  
**Result**: MPNet 3x faster with same accuracy

### **4. Comprehensive Testing**
**Coverage**: Intent, entities, retrieval, routing all tested  
**Automation**: Checkpoint/resume for long test runs  
**Metrics**: Accuracy, timing, failed cases all tracked

### **5. Hybrid Architecture**
**Baseline**: Precise structured queries  
**Embeddings**: Semantic flexibility  
**Together**: Best of both worlds

---

## ğŸš€ **SLIDE 24: Future Improvements**

### Title: Areas for Enhancement

### **1. Baseline Improvements:**
- âŒ Add more query templates (currently 15)
- âŒ Improve entity extraction for implicit traveler types
- âŒ Better handling of typos and variations

### **2. Embedding Improvements:**
- âŒ Balance dataset (more Nigeria visa relationships)
- âŒ Fine-tune embeddings on domain-specific data
- âŒ Handle bidirectional visa queries better

### **3. Architecture Enhancements:**
- âŒ Dynamic weighting of baseline vs embedding scores
- âŒ Learning-based index selection (not just rules)
- âŒ Real-time embedding updates

### **4. Performance Optimizations:**
- âŒ GPU acceleration for embeddings
- âŒ Batch query processing
- âŒ Caching frequent queries

---

## ğŸ¬ **SLIDE 25: Summary & Demo**

### Title: Graph Retrieval Layer - Complete System

**What We Built:**

âœ… **Baseline**: 15 Cypher queries with 85% intent/entity accuracy  
âœ… **Embeddings**: 3 FAISS indexes (hotel, visa, review) with 80-83% retrieval accuracy  
âœ… **Innovation**: Entity-driven multi-index selection for demographic queries  
âœ… **Testing**: Comprehensive test suite (340+ test cases)  
âœ… **Dual Models**: MiniLM vs MPNet comparison (MPNet 3x faster)  

**Key Numbers:**
- ğŸ“Š 15 Cypher query templates
- ğŸ“Š 8 intent types (85.19% accuracy)
- ğŸ“Š 3 FAISS indexes (25 hotels, 220 visas, 50k+ reviews)
- ğŸ“Š 2 embedding models (384 vs 768 dimensions)
- ğŸ“Š 340+ test cases (intent, entity, retrieval, routing)

**Live Demo:**
1. Show baseline query: "Hotels in Paris" â†’ Direct Cypher
2. Show embedding query: "Best hotel for solo travelers" â†’ Multi-index search
3. Show entity-driven routing: traveller_type triggers review embeddings
4. Show score boosting: Hotel appears in both indexes â†’ higher rank

---

## ğŸ“š **APPENDIX SLIDES**

### **A1: Neo4j Schema**
- Nodes: Traveller, Hotel, City, Country, Review
- Relationships: LOCATED_IN, FROM_COUNTRY, WROTE, REVIEWED, STAYED_AT, NEEDS_VISA
- Properties: 50+ attributes across node types

### **A2: File Structure**
```
M3/
â”œâ”€â”€ query_library.py (15 queries)
â”œâ”€â”€ create_embeddings.py (hotel + visa + review)
â”œâ”€â”€ create_embeddings_mpnet.py (2nd model)
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ intent_classifier.py
â”‚   â”œâ”€â”€ entity_extractor.py
â”‚   â”œâ”€â”€ query_builder.py
â”‚   â”œâ”€â”€ query_executor.py
â”‚   â”œâ”€â”€ embedding_generator.py
â”‚   â””â”€â”€ vector_searcher.py
â”œâ”€â”€ Evaluations/
â”‚   â”œâ”€â”€ test_intent_classifier.py
â”‚   â”œâ”€â”€ test_entity_extractor.py
â”‚   â”œâ”€â”€ test_entity_driven_search.py
â”‚   â””â”€â”€ test_embeddings_comprehensive.py
â””â”€â”€ *.faiss files (6 total: 3 per model)
```

### **A3: Test Examples**
Show actual test queries and expected outputs from test files

### **A4: Code Snippets**
Show critical code sections:
- `select_faiss_indexes()` logic
- `multi_index_search()` merge
- `build_hotel_feature_string()` embedding creation

---

**END OF PRESENTATION PLAN**

**Estimated Time**: 25-30 slides Ã— 1-2 minutes = 25-60 minutes (adjust as needed)

**Recommended Order**: Present sequentially - builds understanding from baseline â†’ embeddings â†’ innovation

**Demo Tips**: 
- Keep Neo4j browser open to show graph structure
- Run live queries to demonstrate baseline
- Show FAISS index files and their sizes
- Display test results JSON for evidence
